{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gradient_boosting",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saifharis/Noor/blob/main/gradient_boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "id": "wIA1eHcBHIqf",
        "outputId": "992a2c3e-e77e-4aae-b32c-60f871c0599a"
      },
      "source": [
        "\n",
        " #Importing neccesary packages # Load Libraries \n",
        "from sklearn.ensemble import GradientBoostingRegressor \n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn. model_selection import train_test_split \n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import load_boston \n",
        "from sklearn.metrics import mean_absolute_error \n",
        "from sklearn.metrics import r2_score \n",
        "from numpy import loadtxt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#load the dataset\n",
        "dataset =np.loadtxt('UN_nn_model.csv', delimiter=';')\n",
        "#split into input (X) and output (y) variables\n",
        "X = dataset[:,0:7]\n",
        "y = dataset[:,7]\n",
        "print(X,y)\n",
        "print(y)\n",
        "\n",
        "#Split into training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
        "#X_train=tf.keras.utils.normalize(X_train,axis=-1)\n",
        "print( y_test)\n",
        "\n",
        "#create gradiantboost regressor \n",
        "gradientregressor=GradientBoostingRegressor(max_depth=2,n_estimators=3,learning_rate=1)\n",
        "\n",
        "#train gradient regressor\n",
        "model=gradientregressor.fit(X_train,y_train)\n",
        "y_predict=model.predict(X_test)\n",
        "print(y_predict)\n",
        "\n",
        "#r2_score (y_predict,y_test)\n",
        "errors=[mean_squared_error(y_test,y_predict)for y_predict in gradientregressor.staged_predict(X_test)]\n",
        "best_n_estimators=np.argmin(errors)\n",
        "print(errors)\n",
        "\n",
        "best_regressor=GradientBoostingRegressor(max_depth=2,n_estimators=best_n_estimators,learning_rate=1)\n",
        "best_regressor.fit(X_train,y_train)\n",
        "\n",
        "print(best_n_estimators)\n",
        "\n",
        "\n",
        "y_predict=best_regressor.predict(X_test)\n",
        "mean_absolute_error(y_test,y_predict)\n",
        "print(y_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.50200000e+00  1.44700000e+01  4.87271800e+00  2.18000000e+02\n",
            "   7.90000000e+01  2.11457026e+02  3.40000000e-01]\n",
            " [-1.87200000e+00  7.10000000e+00  4.61762400e+00  2.47000000e+02\n",
            "   1.42000000e+02  3.57492639e+02  3.30000000e-01]\n",
            " [-1.47800000e+00  1.42000000e+01  4.94138932e+00  1.54000000e+02\n",
            "   9.10000000e+01  2.28075949e+02  2.50000000e-01]\n",
            " [-1.30600000e+00  1.44470000e+01  4.86867200e+00  1.45000000e+02\n",
            "   8.00000000e+01  2.02718447e+02  2.70000000e-01]\n",
            " [-1.16300000e+00  6.15000000e+00  4.12493000e+00  3.19000000e+02\n",
            "   1.65000000e+02  4.22205882e+02  2.79411765e-01]\n",
            " [-6.55000000e-01  6.15000000e+00  4.14728469e+00  1.81000000e+02\n",
            "   8.70000000e+01  2.24957143e+02  2.92857143e-01]\n",
            " [-1.03400000e+00  1.49700000e+01  4.42264600e+00  3.27000000e+02\n",
            "   1.27000000e+02  3.37329422e+02  3.28068592e-01]\n",
            " [-1.76400000e+00  1.17900000e+01  5.17583200e+00  1.79000000e+02\n",
            "   8.80000000e+01  2.26828800e+02  2.90000000e-01]\n",
            " [-1.90900000e+00  5.34000000e+00  4.25353400e+00  2.59000000e+02\n",
            "   1.80000000e+02  4.38432602e+02  2.17868339e-01]] [-1.3e-05 -3.3e-06 -1.7e-06 -4.2e-06 -2.6e-05 -6.4e-06  3.6e-06  2.7e-06\n",
            " -1.2e-04]\n",
            "[-1.3e-05 -3.3e-06 -1.7e-06 -4.2e-06 -2.6e-05 -6.4e-06  3.6e-06  2.7e-06\n",
            " -1.2e-04]\n",
            "[-1.2e-04 -4.2e-06 -1.7e-06]\n",
            "[-7.06666667e-06 -7.06666667e-06 -7.06666667e-06]\n",
            "[4.263652222222222e-09, 4.263652222222222e-09, 4.263652222222222e-09]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ec09dda5f980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mbest_regressor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_n_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mbest_regressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_n_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_check_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m             raise ValueError(\"n_estimators must be greater than 0 but \"\n\u001b[0;32m-> 1261\u001b[0;31m                              \"was %r\" % self.n_estimators)\n\u001b[0m\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: n_estimators must be greater than 0 but was 0"
          ]
        }
      ]
    }
  ]
}